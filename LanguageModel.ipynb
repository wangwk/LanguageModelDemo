{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LanguageModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yW44Kxvo2SW"
      },
      "source": [
        "# 利用LSTM和GRU训练语言模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKI9QGpedjK4"
      },
      "source": [
        "import os\r\n",
        "import numpy as np\r\n",
        "import torchtext\r\n",
        "from torchtext.vocab import Vectors\r\n",
        "from tqdm import tqdm\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c_WizXHTb5u"
      },
      "source": [
        "# word vocab construction, idx->word, word->idx, <PAD>索引为0的部分\r\n",
        "def word_set_construction(file_path):\r\n",
        "  with open(file_path, 'r', encoding='utf-8') as f:\r\n",
        "    text = f.readlines()\r\n",
        "  words = [word for sent in text for word in sent.split()]\r\n",
        "  words2idx = {w : i for i, w in enumerate(words, 1)} # 0 for PAD token\r\n",
        "  idx2words = {i : w for i, w in enumerate(words, 1)}\r\n",
        "  PAD_IDX = 0\r\n",
        "  idx2words[PAD_IDX] = '<PAD>'\r\n",
        "  words2idx['<PAD>'] = PAD_IDX\r\n",
        "  return words, idx2words, words2idx\r\n",
        "\r\n",
        "# read corpus: sentences\r\n",
        "def read_corpus(file_path):\r\n",
        "  with open(file_path, 'r', encoding='utf-8') as f:\r\n",
        "    sents = f.readlines()\r\n",
        "  sentences = [sent.strip() for sent in sents]\r\n",
        "  return sentences\r\n",
        "\r\n",
        "# data samples with labels\r\n",
        "def samples_labels(corpus : list, words2idx, idx2words, max_len):\r\n",
        "  samples = []\r\n",
        "  labels = []\r\n",
        "  for sample in tqdm(corpus):\r\n",
        "    words = sample.split()\r\n",
        "    sample_words = [0] * max_len\r\n",
        "    for i, w in enumerate(words[:-1]):\r\n",
        "      sample_words[i] = words2idx[w]\r\n",
        "\r\n",
        "    target_words = [0] * max_len\r\n",
        "    for i, w in enumerate(words[1:]):\r\n",
        "      target_words[i] = words2idx[w]\r\n",
        "\r\n",
        "    samples.append(sample_words)\r\n",
        "    labels.append(target_words)\r\n",
        "\r\n",
        "  return samples, labels\r\n",
        "\r\n",
        "# get batches\r\n",
        "def get_batches(samples, labels, batch_size):\r\n",
        "  batch_data = []\r\n",
        "\r\n",
        "  samples_tensor = torch.tensor(samples, dtype=torch.long)\r\n",
        "  labels_tensor = torch.tensor(labels, dtype=torch.long)\r\n",
        "  num, dim = samples_tensor.size()\r\n",
        "\r\n",
        "  for start in range(0, num, batch_size):\r\n",
        "    end = start + batch_size\r\n",
        "    if end > num:\r\n",
        "      break\r\n",
        "    else:\r\n",
        "      batch_samples = samples_tensor[start : end]\r\n",
        "      batch_labels = samples_tensor[start : end]\r\n",
        "    \r\n",
        "    batch_data.append((batch_samples, batch_labels))\r\n",
        "\r\n",
        "  return batch_data\r\n",
        "\r\n",
        "## RNN-based language models\r\n",
        "class LM_Models(nn.Module):\r\n",
        "  def __init__(self, embedding_dim, hidden_dim, vocab_size, mode):\r\n",
        "    super().__init__()\r\n",
        "    self.hidden_dim = hidden_dim\r\n",
        "    self.word_embedding = nn.Embedding(vocab_size, embedding_dim)\r\n",
        "    if mode == 'LSTM' or 'lstm':\r\n",
        "      self.model = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\r\n",
        "    elif mode == 'GRU' or 'gru':\r\n",
        "      self.model = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\r\n",
        "    elif mode == 'RNN' or 'rnn':\r\n",
        "      self.model = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\r\n",
        "    self.hidden2word = nn.Linear(hidden_dim, vocab_size)\r\n",
        "\r\n",
        "  def forward(self, data):\r\n",
        "    embeds = self.word_embedding(data)\r\n",
        "    model_out, (h_n, c_n) = self.model(embeds)\r\n",
        "    target_embed = self.hidden2word(model_out.contiguous().view(-1, self.hidden_dim))\r\n",
        "    mask = (data != idx).view(-1)\r\n",
        "    pure_target = target_embed[mask]\r\n",
        "    target_scores = F.log_softmax(pure_target, dim=1)\r\n",
        "    return target_scores\r\n",
        "\r\n",
        "# evaluation \r\n",
        "def accuracy_score(y_hat, y):\r\n",
        "  y_hat = y_hat.argmax(dim=1)\r\n",
        "  num_pre_real = torch.eq(y_hat, y.view(-1))\r\n",
        "  score = num_pre_real.sum().item() / num_pre_real.size()[0]\r\n",
        "  return score\r\n",
        "\r\n",
        "def evaluate(model, data):\r\n",
        "  model.eval()\r\n",
        "  total_acc = 0.\r\n",
        "  total_count = 0.\r\n",
        "  for x, y in data:\r\n",
        "    mask = y != idx\r\n",
        "    pure_y = y[mask]\r\n",
        "    with torch.no_grad():\r\n",
        "      target_scores = model(x)\r\n",
        "    total_count += 1\r\n",
        "    acc = accuracy_score(target_scores, pure_y)\r\n",
        "    total_acc += acc\r\n",
        "  \r\n",
        "  acc = total_acc / total_count\r\n",
        "  # model.train()\r\n",
        "  return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppyG_LAhK5W3",
        "outputId": "0b744cb5-a76e-4792-ede1-8e5f4a3229e0"
      },
      "source": [
        "# 定义文件所在路径\r\n",
        "vocab_file = './bobsue.voc.txt'\r\n",
        "train_file = './bobsue.lm.train.txt'\r\n",
        "val_file = './bobsue.lm.dev.txt'\r\n",
        "test_file = './bobsue.lm.dev.txt'\r\n",
        "\r\n",
        "MAX_LEN = 20\r\n",
        "BATCH_SIZE = 128\r\n",
        "# get vocabs\r\n",
        "words, idx2words, words2idx = word_set_construction(vocab_file)\r\n",
        "# train batches data\r\n",
        "train_corpus = read_corpus(train_file)\r\n",
        "train_samples, train_labels = samples_labels(train_corpus, words2idx, idx2words, MAX_LEN)\r\n",
        "train_batch_data = get_batches(train_samples, train_labels, BATCH_SIZE)\r\n",
        "# val batches data\r\n",
        "val_corpus = read_corpus(val_file)\r\n",
        "val_samples, val_labels = samples_labels(val_corpus, words2idx, idx2words, MAX_LEN)\r\n",
        "val_batch_data = get_batches(val_samples, val_labels, BATCH_SIZE)\r\n",
        "# test batches data\r\n",
        "test_corpus = read_corpus(test_file)\r\n",
        "test_samples, test_labels = samples_labels(test_corpus, words2idx, idx2words, MAX_LEN)\r\n",
        "test_batch_data = get_batches(test_samples, test_labels, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6036/6036 [00:00<00:00, 230807.55it/s]\n",
            "100%|██████████| 750/750 [00:00<00:00, 197732.60it/s]\n",
            "100%|██████████| 750/750 [00:00<00:00, 136355.79it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13XccFyuWzje",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96409d8a-c285-4314-e726-dc2b75d93a51"
      },
      "source": [
        "# function to train\r\n",
        "EMBEDDING_DIM = 200\r\n",
        "HIDDEN_DIM = 200\r\n",
        "MODE = 'LSTM'\r\n",
        "model = LM_Models(EMBEDDING_DIM, HIDDEN_DIM, len(words2idx), mode=MODE)\r\n",
        "GRAD_CLIP = 5.\r\n",
        "NUM_EPOCHS = 10\r\n",
        "LR = 0.001\r\n",
        "\r\n",
        "val_acces = []\r\n",
        "loss_function = nn.NLLLoss()\r\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\r\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, 0.5)\r\n",
        "\r\n",
        "Model_Save_Name = 'LM-' + MODE + '-best.pth'\r\n",
        "# print parameters\r\n",
        "sum_ = 0\r\n",
        "for name, param in model.named_parameters():\r\n",
        "  mul = 1\r\n",
        "  for size_ in param.shape:\r\n",
        "    mul *= size_\r\n",
        "  sum_ += mul\r\n",
        "  print('%14s : %s' % (name, param.shape))\r\n",
        "print('Total Num. of params：', sum_)\r\n",
        "\r\n",
        "# train, val and test\r\n",
        "for epoch in range(NUM_EPOCHS):\r\n",
        "  model.train()\r\n",
        "  print('epoch:{}'.format(epoch).center(51, '*'))\r\n",
        "  idx = 0\r\n",
        "  acc_list = []\r\n",
        "  for i, (x, y) in enumerate(train_batch_data):  # x: train, y: label\r\n",
        "    mask = y != idx\r\n",
        "    pure_y = y[mask]\r\n",
        "    # feedforward\r\n",
        "    model.zero_grad()\r\n",
        "    target_scores = model(x)\r\n",
        "    acc = accuracy_score(target_scores, pure_y)\r\n",
        "    acc_list.append(acc)\r\n",
        "    # loss function\r\n",
        "    loss = loss_function(target_scores, pure_y)\r\n",
        "    # backpropagagtion\r\n",
        "    loss.backward()\r\n",
        "    # optim\r\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\r\n",
        "    optimizer.step()\r\n",
        "    if i % 20 == 0:\r\n",
        "      print('epoch:{} item:{} loss:{:.4} acc:{:.4}'.format(epoch, i, loss.item(), acc))\r\n",
        "\r\n",
        "  print('Epoch:{} avg acc:{:.4}'.format(epoch, sum(acc_list)/len(acc_list)))\r\n",
        "\r\n",
        "  # eval\r\n",
        "  val_acc = evaluate(model, val_batch_data)\r\n",
        "  if len(val_acces) == 0 or val_acc > max(val_acces):\r\n",
        "    print('Best model, val Accuracy: {:.4}'.format(val_acc))\r\n",
        "    torch.save(model.state_dict(), Model_Save_Name)\r\n",
        "  else:\r\n",
        "    print('Current val Accuracy: {:.4}'.format(val_acc))\r\n",
        "    scheduler.step()\r\n",
        "  val_acces.append(val_acc)\r\n",
        "\r\n",
        "  # test\r\n",
        "  test_acc = evaluate(model, test_batch_data)\r\n",
        "  print('Test data accuracy: {:.4}'.format(test_acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word_embedding.weight : torch.Size([1499, 200])\n",
            "model.weight_ih_l0 : torch.Size([800, 200])\n",
            "model.weight_hh_l0 : torch.Size([800, 200])\n",
            "model.bias_ih_l0 : torch.Size([800])\n",
            "model.bias_hh_l0 : torch.Size([800])\n",
            "hidden2word.weight : torch.Size([1499, 200])\n",
            "hidden2word.bias : torch.Size([1499])\n",
            "Total Num. of params： 922699\n",
            "**********************epoch:0**********************\n",
            "epoch:0 item:0 loss:7.309 acc:0.0\n",
            "epoch:0 item:20 loss:4.835 acc:0.3166\n",
            "epoch:0 item:40 loss:3.215 acc:0.5443\n",
            "Epoch:0 avg acc:0.4333\n",
            "Best model, val Accuracy: 0.5966\n",
            "Test data accuracy: 0.5966\n",
            "**********************epoch:1**********************\n",
            "epoch:1 item:0 loss:2.871 acc:0.5813\n",
            "epoch:1 item:20 loss:1.992 acc:0.7365\n",
            "epoch:1 item:40 loss:1.471 acc:0.8169\n",
            "Epoch:1 avg acc:0.7398\n",
            "Best model, val Accuracy: 0.8556\n",
            "Test data accuracy: 0.8556\n",
            "**********************epoch:2**********************\n",
            "epoch:2 item:0 loss:1.318 acc:0.849\n",
            "epoch:2 item:20 loss:0.8738 acc:0.9154\n",
            "epoch:2 item:40 loss:0.6894 acc:0.9378\n",
            "Epoch:2 avg acc:0.9077\n",
            "Best model, val Accuracy: 0.9504\n",
            "Test data accuracy: 0.9504\n",
            "**********************epoch:3**********************\n",
            "epoch:3 item:0 loss:0.6451 acc:0.9358\n",
            "epoch:3 item:20 loss:0.4084 acc:0.9686\n",
            "epoch:3 item:40 loss:0.3337 acc:0.9785\n",
            "Epoch:3 avg acc:0.9684\n",
            "Best model, val Accuracy: 0.9789\n",
            "Test data accuracy: 0.9789\n",
            "**********************epoch:4**********************\n",
            "epoch:4 item:0 loss:0.3385 acc:0.9796\n",
            "epoch:4 item:20 loss:0.2073 acc:0.9916\n",
            "epoch:4 item:40 loss:0.1712 acc:0.995\n",
            "Epoch:4 avg acc:0.9901\n",
            "Best model, val Accuracy: 0.9902\n",
            "Test data accuracy: 0.9902\n",
            "**********************epoch:5**********************\n",
            "epoch:5 item:0 loss:0.1797 acc:0.9964\n",
            "epoch:5 item:20 loss:0.1139 acc:0.9979\n",
            "epoch:5 item:40 loss:0.09362 acc:0.9986\n",
            "Epoch:5 avg acc:0.9964\n",
            "Best model, val Accuracy: 0.9956\n",
            "Test data accuracy: 0.9956\n",
            "**********************epoch:6**********************\n",
            "epoch:6 item:0 loss:0.09842 acc:0.9993\n",
            "epoch:6 item:20 loss:0.06596 acc:0.9993\n",
            "epoch:6 item:40 loss:0.05467 acc:0.9986\n",
            "Epoch:6 avg acc:0.9984\n",
            "Best model, val Accuracy: 0.9979\n",
            "Test data accuracy: 0.9979\n",
            "**********************epoch:7**********************\n",
            "epoch:7 item:0 loss:0.05699 acc:0.9993\n",
            "epoch:7 item:20 loss:0.04069 acc:0.9993\n",
            "epoch:7 item:40 loss:0.03395 acc:1.0\n",
            "Epoch:7 avg acc:0.999\n",
            "Best model, val Accuracy: 0.999\n",
            "Test data accuracy: 0.999\n",
            "**********************epoch:8**********************\n",
            "epoch:8 item:0 loss:0.03587 acc:0.9993\n",
            "epoch:8 item:20 loss:0.02727 acc:1.0\n",
            "epoch:8 item:40 loss:0.02269 acc:1.0\n",
            "Epoch:8 avg acc:0.9995\n",
            "Best model, val Accuracy: 0.9994\n",
            "Test data accuracy: 0.9994\n",
            "**********************epoch:9**********************\n",
            "epoch:9 item:0 loss:0.02495 acc:1.0\n",
            "epoch:9 item:20 loss:0.01979 acc:1.0\n",
            "epoch:9 item:40 loss:0.01642 acc:1.0\n",
            "Epoch:9 avg acc:0.9999\n",
            "Best model, val Accuracy: 0.9996\n",
            "Test data accuracy: 0.9996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bn8tXD-_uao"
      },
      "source": [
        "# print incorrect prediction\r\n",
        "def print_incorrect_prediction(model, data):\r\n",
        "  model.eval()\r\n",
        "  incorrect_words = []\r\n",
        "  for x, y in data:\r\n",
        "    mask = [y != 0]\r\n",
        "    y = y[mask]\r\n",
        "    with torch.no_grad():\r\n",
        "      target_scores = model(x)\r\n",
        "    y_hat = target_scores.argmax(dim=1)\r\n",
        "\r\n",
        "    for i, j in zip(y_hat.tolist(), y.tolist()):\r\n",
        "      if i != j:\r\n",
        "        incorrect_words.append('|'.join([idx2words[i], idx2words[j]]))\r\n",
        "  return incorrect_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3oYVG_-TFG_",
        "outputId": "fdfe0089-5a62-4265-fee3-a23999cfc362"
      },
      "source": [
        "model.load_state_dict(torch.load(Model_Save_Name))\r\n",
        "incorrect_predictions = print_incorrect_prediction(model, test_batch_data)\r\n",
        "for inc_pred in incorrect_predictions:\r\n",
        "  print(inc_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "birthday|bags\n",
            "meeting|calling\n",
            ".|fresh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtTNP35mDrbM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}